{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data wrangling the Incident's Json and generate incidents.csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths for JSON input and CSV output\n",
    "json_folder_path = Path.cwd().parents[1] / 'json_renamed'\n",
    "csv_folder_path = Path.cwd().parents[1] / 'csv_datasets'\n",
    "\n",
    "# Ensure the CSV directory exists\n",
    "csv_folder_path.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_json(data, parent_key='', sep='_'):\n",
    "    \"\"\"\n",
    "    Recursively flattens a nested JSON dictionary, handling both dictionaries and lists.\n",
    "    \"\"\"\n",
    "    items = {}\n",
    "    if isinstance(data, dict):\n",
    "        for k, v in data.items():\n",
    "            new_key = f\"{parent_key}{sep}{k}\" if parent_key else k\n",
    "            if isinstance(v, (dict, list)):\n",
    "                items.update(flatten_json(v, new_key, sep=sep))\n",
    "            else:\n",
    "                items[new_key] = v\n",
    "    elif isinstance(data, list):\n",
    "        for i, v in enumerate(data):\n",
    "            new_key = f\"{parent_key}{sep}{i}\" if parent_key else str(i)\n",
    "            if isinstance(v, (dict, list)):\n",
    "                items.update(flatten_json(v, new_key, sep=sep))\n",
    "            else:\n",
    "                items[new_key] = v\n",
    "    return items\n",
    "\n",
    "def extract_incidents(json_data):\n",
    "    \"\"\"\n",
    "    Extracts and flattens all incident data from the JSON dynamically.\n",
    "    \"\"\"\n",
    "    flattened_data = []\n",
    "\n",
    "    # Loop through each incident in the JSON data\n",
    "    for incident in json_data.get('incidents', []):\n",
    "        # Flatten each incident recursively\n",
    "        flat_incident = flatten_json(incident)\n",
    "        flattened_data.append(flat_incident)\n",
    "\n",
    "    # Return a DataFrame from the flattened data\n",
    "    return pd.DataFrame(flattened_data)\n",
    "\n",
    "# List to store DataFrames for each file\n",
    "incidents_dataframes = []\n",
    "\n",
    "# Iterate over all files in the JSON folder\n",
    "for filename in os.listdir(json_folder_path):\n",
    "    try:\n",
    "        # Process only JSON files that contain 'incidents' in their name\n",
    "        if filename.endswith('.json') and 'incidents' in filename:\n",
    "            json_file_path = os.path.join(json_folder_path, filename)\n",
    "\n",
    "            with open(json_file_path, 'r', encoding='utf-8') as file:\n",
    "                json_data = json.load(file)\n",
    "\n",
    "            # Extract incidents data from the JSON file\n",
    "            df = extract_incidents(json_data)\n",
    "\n",
    "            # Add 'date' and 'code' from the filename to the DataFrame\n",
    "            date, code, _ = filename.split('_')[1:4]\n",
    "            df.insert(0, 'date', date)\n",
    "            df.insert(1, 'code', code)\n",
    "\n",
    "            # Append the DataFrame to the list\n",
    "            incidents_dataframes.append(df)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing file {filename}: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Consolidated data saved to /Users/fernandaalves/Documents/code_studies/palmeiras_analytics_br/csv_datasets/incidents.csv\n"
     ]
    }
   ],
   "source": [
    "# Filter out empty or all-NA DataFrames\n",
    "incidents_dataframes = [df for df in incidents_dataframes if not df.empty and not df.isna().all().all()]\n",
    "\n",
    "# Concatenate all valid DataFrames into a single DataFrame\n",
    "result_df = pd.concat(incidents_dataframes, ignore_index=True)\n",
    "\n",
    "# Save the consolidated DataFrame to a CSV file\n",
    "result_df.to_csv(csv_folder_path / 'incidents.csv', index=False)\n",
    "\n",
    "print(f\"Consolidated data saved to {csv_folder_path / 'incidents.csv'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Key Adjustments:\n",
    "\n",
    "    Function Renaming: Changed ExtractorIncidents to extract_incidents to follow Python naming conventions (snake_case).\n",
    "    Efficient Data Extraction: Removed redundant checks and directly appended data to the template dictionary.\n",
    "    Error Handling: Improved error handling to provide more informative messages when processing files.\n",
    "    Code Clarity: Simplified comments for better readability while maintaining essential explanations.\n",
    "    Improved DataFrame Management: Added filtering for empty or all-NA DataFrames before concatenating.\n",
    "    Dynamic Extraction with flatten_json: The flatten_json function is used to recursively flatten each incident, capturing all fields and subfields, regardless of the depth of nesting.\n",
    "    Increased Flexibility: The code is now adaptable to different JSON structures, ensuring that all data is extracted, even if the format varies between files.\n",
    "    Elimination of Empty Fields: The dynamic use of keys eliminates the need for predefined lists, capturing all available data and minimizing empty fields in the final CSV."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
