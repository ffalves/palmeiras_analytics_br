{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths for JSON input and CSV output\n",
    "json_folder_path = Path.cwd().parents[1] / 'json_renamed'\n",
    "csv_folder_path = Path.cwd().parents[1] / 'csv_datasets'\n",
    "\n",
    "# Ensure the CSV directory exists\n",
    "csv_folder_path.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a mapping template to convert shotmap data into a standardized dictionary format\n",
    "\n",
    "def ExtractShotmap(shotmap_data):\n",
    "    template = {\n",
    "        'is_home': [],\n",
    "        'shot_type': [],\n",
    "        'situation': [],\n",
    "        'body_part': [],\n",
    "        'reversed_period_time': [],\n",
    "        'reversed_period_time_sec': [],\n",
    "        'goal_mouth_loc': [],\n",
    "        'time': [],\n",
    "        'time_sec': [],\n",
    "        'incident_type': [],\n",
    "\n",
    "        'player_name': [],\n",
    "        'player_slug': [],\n",
    "        'player_id': [],\n",
    "        'player_position': [],\n",
    "        'player_usercount': [],\n",
    "\n",
    "        'xg': [],\n",
    "        'xgot': [],\n",
    "\n",
    "        'player_x': [],\n",
    "        'player_y': [],\n",
    "        'player_z': [],\n",
    "\n",
    "        'goal_x': [],\n",
    "        'goal_y': [],\n",
    "        'goal_z': [],\n",
    "\n",
    "        'block_x': [],\n",
    "        'block_y': [],\n",
    "        'block_z': [],\n",
    "\n",
    "        'draw_start_x': [],\n",
    "        'draw_end_x': [],\n",
    "        'draw_goal_x': [],\n",
    "\n",
    "        'draw_start_y': [],\n",
    "        'draw_end_y': [],\n",
    "        'draw_goal_y': []\n",
    "    }\n",
    "\n",
    "    # Iterate through each entry in the shotmap data\n",
    "    for info in shotmap_data['shotmap']:\n",
    "        # Extract basic shot information\n",
    "        template['is_home'].append(info.get('isHome', None))\n",
    "        template['shot_type'].append(info.get('shotType', None))\n",
    "        template['situation'].append(info.get('situation', None))\n",
    "        template['body_part'].append(info.get('bodyPart', None))\n",
    "        template['reversed_period_time'].append(info.get('reversedPeriodTime', None))\n",
    "        template['reversed_period_time_sec'].append(info.get('reversedPeriodTimeSeconds', None))\n",
    "        template['goal_mouth_loc'].append(info.get('goalMouthLocation', None))\n",
    "        template['time'].append(info.get('time', None))\n",
    "        template['time_sec'].append(info.get('timeSeconds', None))\n",
    "        template['incident_type'].append(info.get('incidentType', None))\n",
    "\n",
    "        # Extract player information\n",
    "        player_info = info.get('player', {})\n",
    "        template['player_name'].append(player_info.get('name', None))\n",
    "        template['player_slug'].append(player_info.get('slug', None))\n",
    "        template['player_id'].append(player_info.get('id', None))\n",
    "        template['player_position'].append(player_info.get('position', None))\n",
    "        template['player_usercount'].append(player_info.get('userCount', None))\n",
    "\n",
    "        # Extract expected goals (xG) information\n",
    "        template['xg'].append(info.get('xg', None))\n",
    "        template['xgot'].append(info.get('xgot', None))\n",
    "\n",
    "        # Extract player coordinates\n",
    "        coordinates = info.get('playerCoordinates', {})\n",
    "        template['player_x'].append(coordinates.get('x', None))\n",
    "        template['player_y'].append(coordinates.get('y', None))\n",
    "        template['player_z'].append(coordinates.get('z', None))\n",
    "\n",
    "        # Extract goal mouth coordinates\n",
    "        goal_coordinates = info.get('goalMouthCoordinates', {})\n",
    "        template['goal_x'].append(goal_coordinates.get('x', None))\n",
    "        template['goal_y'].append(goal_coordinates.get('y', None))\n",
    "        template['goal_z'].append(goal_coordinates.get('z', None))\n",
    "\n",
    "        # Extract block coordinates\n",
    "        block_coordinates = info.get('blockCoordinates', {})\n",
    "        template['block_x'].append(block_coordinates.get('x', None))\n",
    "        template['block_y'].append(block_coordinates.get('y', None))\n",
    "        template['block_z'].append(block_coordinates.get('z', None))\n",
    "\n",
    "        # Extract drawing information for visualization\n",
    "        draw = info.get('draw', {})\n",
    "        template['draw_start_x'].append(draw.get('start', {}).get('x', None))\n",
    "        template['draw_end_x'].append(draw.get('end', {}).get('x', None))\n",
    "        template['draw_goal_x'].append(draw.get('goal', {}).get('x', None))\n",
    "\n",
    "        template['draw_start_y'].append(draw.get('start', {}).get('y', None))\n",
    "        template['draw_end_y'].append(draw.get('end', {}).get('y', None))\n",
    "        template['draw_goal_y'].append(draw.get('goal', {}).get('y', None)) \n",
    "\n",
    "    # Return the filled template\n",
    "    return template\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list to store the DataFrames\n",
    "shotmaps_df = []\n",
    "\n",
    "# Iterate through all files in the JSON folder\n",
    "for filename in os.listdir(json_folder_path):\n",
    "    try:\n",
    "        # Check if the file ends with '.json' and contains 'shotmap' in its name\n",
    "        if filename.endswith('.json') and 'shotmap' in filename:\n",
    "            # Construct the full path to the file\n",
    "            json_file_path = os.path.join(json_folder_path, filename)\n",
    "\n",
    "            # Open the file and load the JSON data\n",
    "            with open(json_file_path, 'r', encoding='utf-8') as file:\n",
    "                data = json.load(file)\n",
    "\n",
    "            # Check if 'shotmap' data exists in the JSON\n",
    "            if 'shotmap' in data:\n",
    "                # Extract the shotmap data from the JSON file\n",
    "                shotmap_template = ExtractShotmap(data)\n",
    "\n",
    "                # Convert the dictionary into a DataFrame\n",
    "                df = pd.DataFrame(shotmap_template)\n",
    "\n",
    "                # Extract the date and code from the filename and insert them into the DataFrame columns names\n",
    "                date, code, _ = filename.split('_')[1:4]\n",
    "                df.insert(0, 'date', date)\n",
    "                df.insert(1, 'code', code)\n",
    "                df['filename'] = filename  # Add the filename as a column\n",
    "\n",
    "                # Append the DataFrame to the list\n",
    "                shotmaps_df.append(df)\n",
    "\n",
    "    # Handle exceptions\n",
    "    except Exception as e:\n",
    "        print(f'Error processing the file {filename}: {str(e)}')\n",
    "\n",
    "# Filter out DataFrames that are either empty or contain only NA values\n",
    "shotmaps_df = [df for df in shotmaps_df if not df.empty and not df.isna().all().all()]\n",
    "\n",
    "# Concatenate all non-empty DataFrames into a single DataFrame\n",
    "if shotmaps_df:\n",
    "    result_df = pd.concat(shotmaps_df, ignore_index=True)\n",
    "\n",
    "    # Save the concatenated DataFrame to a CSV file\n",
    "    result_df.to_csv(csv_folder_path / 'shotmaps.csv', index=False)\n",
    "else:\n",
    "    print('No DataFrame to concatenate.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_json(data, parent_key='', sep='_'):\n",
    "    \"\"\"\n",
    "    Recursively flattens a nested JSON dictionary or list.\n",
    "    \"\"\"\n",
    "    items = {}\n",
    "    if isinstance(data, dict):\n",
    "        for k, v in data.items():\n",
    "            new_key = f\"{parent_key}{sep}{k}\" if parent_key else k\n",
    "            if isinstance(v, dict):\n",
    "                items.update(flatten_json(v, new_key, sep=sep))\n",
    "            elif isinstance(v, list):\n",
    "                for i, item in enumerate(v):\n",
    "                    if isinstance(item, (dict, list)):\n",
    "                        items.update(flatten_json(item, f\"{new_key}{sep}{i}\", sep=sep))\n",
    "                    else:\n",
    "                        items[f\"{new_key}{sep}{i}\"] = item\n",
    "            else:\n",
    "                items[new_key] = v\n",
    "    elif isinstance(data, list):\n",
    "        for i, item in enumerate(data):\n",
    "            items.update(flatten_json(item, f\"{parent_key}{sep}{i}\", sep=sep))\n",
    "    else:\n",
    "        items[parent_key] = data\n",
    "    return items\n",
    "\n",
    "def extract_shotmap(shotmap_data):\n",
    "    \"\"\"\n",
    "    Extracts all shotmap data from JSON using a dynamic approach.\n",
    "    \"\"\"\n",
    "    flattened_data = []\n",
    "\n",
    "    # Loop through each shotmap entry in the JSON data\n",
    "    for shot in shotmap_data.get('shotmap', []):\n",
    "        # Flatten each shot entry and append to the list\n",
    "        flat_shot = flatten_json(shot)\n",
    "        flattened_data.append(flat_shot)\n",
    "\n",
    "    # Return a DataFrame from the flattened data\n",
    "    return pd.DataFrame(flattened_data)\n",
    "\n",
    "# List to store DataFrames for each file\n",
    "shotmaps_dataframes = []\n",
    "\n",
    "# Iterate over all files in the JSON folder\n",
    "for filename in os.listdir(json_folder_path):\n",
    "    try:\n",
    "        # Process only JSON files that contain 'shotmap' in their name\n",
    "        if filename.endswith('.json') and 'shotmap' in filename:\n",
    "            json_file_path = os.path.join(json_folder_path, filename)\n",
    "\n",
    "            with open(json_file_path, 'r', encoding='utf-8') as file:\n",
    "                json_data = json.load(file)\n",
    "\n",
    "            # Extract shotmap data from the JSON file\n",
    "            df = extract_shotmap(json_data)\n",
    "\n",
    "            # Add 'date' and 'code' from the filename to the DataFrame\n",
    "            date, code, _ = filename.split('_')[1:4]\n",
    "            df.insert(0, 'date', date)\n",
    "            df.insert(1, 'code', code)\n",
    "\n",
    "            # Append the DataFrame to the list\n",
    "            shotmaps_dataframes.append(df)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing file {filename}: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Consolidated data saved to /Users/fernandaalves/Documents/code_studies/palmeiras_analytics_br/csv_datasets/shotmaps.csv\n"
     ]
    }
   ],
   "source": [
    "# Filter out empty or all-NA DataFrames\n",
    "shotmaps_dataframes = [df for df in shotmaps_dataframes if not df.empty and not df.isna().all().all()]\n",
    "\n",
    "# Concatenate all valid DataFrames into a single DataFrame\n",
    "if shotmaps_dataframes:\n",
    "    result_df = pd.concat(shotmaps_dataframes, ignore_index=True)\n",
    "\n",
    "    # Save the consolidated DataFrame to a CSV file\n",
    "    result_df.to_csv(csv_folder_path / 'shotmaps.csv', index=False)\n",
    "    print(f\"Consolidated data saved to {csv_folder_path / 'shotmaps.csv'}\")\n",
    "else:\n",
    "    print('No DataFrame to concatenate.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Key Adjustments\n",
    "\n",
    "    Dynamic Extraction with flatten_json: The flatten_json function has been enhanced to recursively process both dictionaries and lists. This ensures that every level of nested data is flattened and captured in the final DataFrame.\n",
    "\n",
    "    Increased Flexibility: This updated approach is highly adaptable to different JSON structures. It can handle any depth or variation in the data format, ensuring that all available data is extracted.\n",
    "\n",
    "    Reduced Empty Fields: By dynamically flattening the entire JSON structure, the code minimizes the likelihood of missing or empty fields in the final CSV output."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
