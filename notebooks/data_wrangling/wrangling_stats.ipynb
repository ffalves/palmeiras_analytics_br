{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data wrangling the Stats's Json and generate stats.csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths for JSON input and CSV output\n",
    "json_folder_path = Path.cwd().parents[1] / 'json_renamed'\n",
    "csv_folder_path = Path.cwd().parents[1] / 'csv_datasets'\n",
    "\n",
    "# Ensure the CSV directory exists\n",
    "csv_folder_path.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Consolidated data saved to /Users/fernandaalves/Documents/code_studies/palmeiras_analytics_br/csv_datasets/stats.csv\n"
     ]
    }
   ],
   "source": [
    "def flatten_json(data, parent_key='', sep='_'):\n",
    "    \"\"\"\n",
    "    Recursively flattens a nested JSON dictionary.\n",
    "    \"\"\"\n",
    "    items = {}\n",
    "    for k, v in data.items():\n",
    "        new_key = f\"{parent_key}{sep}{k}\" if parent_key else k\n",
    "        if isinstance(v, dict):\n",
    "            items.update(flatten_json(v, new_key, sep=sep))\n",
    "        elif isinstance(v, list):\n",
    "            for i, item in enumerate(v):\n",
    "                if isinstance(item, dict):\n",
    "                    items.update(flatten_json(item, f\"{new_key}{i}\", sep=sep))\n",
    "                else:\n",
    "                    items[f\"{new_key}{i}\"] = item\n",
    "        else:\n",
    "            items[new_key] = v\n",
    "    return items\n",
    "\n",
    "def extract_stats(data):\n",
    "    \"\"\"\n",
    "    Extracts and flattens all statistics data into a standardized format.\n",
    "    \"\"\"\n",
    "    flattened_data = []\n",
    "\n",
    "    # Loop through each period in the JSON data\n",
    "    for period in data.get('statistics', []):\n",
    "        period_flat = flatten_json(period, 'period')\n",
    "        # Extract statistics for each group\n",
    "        for group in period.get('groups', []):\n",
    "            group_flat = flatten_json(group, 'group')\n",
    "            # Extract statistics for each item in the group\n",
    "            for stat_item in group.get('statisticsItems', []):\n",
    "                item_flat = flatten_json(stat_item, 'item')\n",
    "                # Combine period, group, and item data\n",
    "                combined_flat = {**period_flat, **group_flat, **item_flat}\n",
    "                flattened_data.append(combined_flat)\n",
    "\n",
    "    # Return a DataFrame from the flattened data\n",
    "    return pd.DataFrame(flattened_data)\n",
    "\n",
    "# List to store DataFrames for each file\n",
    "stats_dataframes = []\n",
    "\n",
    "# Iterate over all files in the JSON folder\n",
    "for filename in os.listdir(json_folder_path):\n",
    "    try:\n",
    "        # Process only JSON files that contain 'stats' in their name\n",
    "        if filename.endswith('.json') and 'stats' in filename:\n",
    "            json_file_path = os.path.join(json_folder_path, filename)\n",
    "\n",
    "            with open(json_file_path, 'r', encoding='utf-8') as file:\n",
    "                json_data = json.load(file)\n",
    "\n",
    "            # Check if 'statistics' data exists in the JSON\n",
    "            if 'statistics' in json_data:\n",
    "                # Extract statistics data from the JSON file\n",
    "                df = extract_stats(json_data)\n",
    "\n",
    "                # Add 'date' and 'code' from the filename to the DataFrame\n",
    "                date, code, _ = filename.split('_')[1:4]\n",
    "                df.insert(0, 'date', date)\n",
    "                df.insert(1, 'code', code)\n",
    "\n",
    "                # Append the DataFrame to the list\n",
    "                stats_dataframes.append(df)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing file {filename}: {str(e)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out empty or all-NA DataFrames\n",
    "stats_dataframes = [df for df in stats_dataframes if not df.empty and not df.isna().all().all()]\n",
    "\n",
    "# Concatenate all valid DataFrames into a single DataFrame\n",
    "if stats_dataframes:\n",
    "    result_df = pd.concat(stats_dataframes, ignore_index=True)\n",
    "    # Save the consolidated DataFrame to a CSV file\n",
    "    result_df.to_csv(csv_folder_path / 'stats.csv', index=False)\n",
    "    print(f\"Consolidated data saved to {csv_folder_path / 'stats.csv'}\")\n",
    "else:\n",
    "    print('No DataFrame to concatenate.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Key Improvements\n",
    "\n",
    "    Dynamic Data Extraction: The updated flatten_json function uses a recursive approach to extract all nested information, ensuring that no data is missed regardless of the depth of the structure.\n",
    "    Flexible Data Handling: The code dynamically adapts to the different JSON structures, ensuring that all data is extracted even if the format varies between files.\n",
    "    Efficient Data Concatenation: Only valid DataFrames (non-empty and containing at least some non-NA values) are concatenated, minimizing the risk of introducing empty or invalid rows into the final CSV."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
